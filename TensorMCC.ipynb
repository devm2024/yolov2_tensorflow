{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10b0d9290>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nN2B8Igp1WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ced0410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[15,:].reshape(28,28))\n",
    "#mnist.train.images[11,:].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 55000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    X_train=mnist.train.images.T\n",
    "    X_test=mnist.test.images.T\n",
    "    Y_train=mnist.train.labels.T\n",
    "    Y_test=mnist.test.labels.T\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Provide Mini-batches\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    num_complete_minibatches=int(num_complete_minibatches)\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Building your neural network in tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "X_train,  X_test,Y_train, Y_test = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 10000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create_placeholders\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    X = tf.placeholder(dtype=\"float\", shape=(n_x, None), name='X')\n",
    "    Y = tf.placeholder(dtype=\"float\", shape=(n_y, None), name='Y')\n",
    "    \n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize_parameters\n",
    "tf.reset_default_graph()\n",
    "def initialize_parameters():\n",
    "    #12288 is the size of flattened image, don't worry\n",
    "    # 25 is the size of nodes in next layer, building features\n",
    "    # 12 is the size of nodes in next layer, building secondary features\n",
    "    # 6 is the size of nodes in last layer which is our output\n",
    "    # We have total of 3 layers in our neural net\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 784]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\", [40,784], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable('b1', [40,1], initializer= tf.zeros_initializer())\n",
    "    W2 = tf.get_variable('W2', [20,40], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable('b2', [20,1], initializer= tf.zeros_initializer())\n",
    "    W3 = tf.get_variable('W3', [10,20], initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable('b3', [10,1], initializer= tf.zeros_initializer())\n",
    "    \n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    \n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                  # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                 # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                               # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                           # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MatMul:0' shape=(25, 2000) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    '''\n",
    "    # Minimize error using cross entropy for logistic regression\n",
    "    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(A3), reduction_indices=1))\n",
    "    '''\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Final Model\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 800, minibatch_size = 64, print_cost = True):\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "\n",
    "    #X_train=tf.cast(X_train, tf.float32) \n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "\n",
    "    cost = compute_cost(Z3, Y)\n",
    "\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.206186\n",
      "Cost after epoch 100: 0.028724\n",
      "Cost after epoch 200: 0.002917\n",
      "Cost after epoch 300: 0.000123\n",
      "Cost after epoch 400: 0.000015\n",
      "Cost after epoch 500: 0.000002\n",
      "Cost after epoch 600: 0.000001\n",
      "Cost after epoch 700: 0.000000\n",
      "Cost after epoch 800: 0.000000\n",
      "Cost after epoch 900: 0.000000\n",
      "Cost after epoch 1000: 0.000000\n",
      "Cost after epoch 1100: 0.000000\n",
      "Cost after epoch 1200: 0.000000\n",
      "Cost after epoch 1300: 0.000000\n",
      "Cost after epoch 1400: 0.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d0fbf10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "('Train Accuracy:', 1.0)\n",
      "('Test Accuracy:', 0.96740001)\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
